# well come to the web scraping class 
# class agenda:
# 1. what is web scraping
# 2. why web scraping
# 3. how to do web scraping
# 4. web scraping tools
# 5. web scraping libraries
# 6. web scraping examples
# 7. web scraping challenges
# 8. web scraping best practices    
# 9. web scraping resources
# 10. web scraping projects
# 11. web scraping jobs
# 12. web scraping future
# 13. web scraping questions
# 14. web scraping answers


# 1. what is web scraping
- web scraping is a technique to extract data from websites. it is also called web harvesting or web data extraction.
- web scraping is a process of automating the extraction of data from websites.
- web scraping is a process of extracting data from websites and saving it in a structured format.
- web scraping is a process of extracting data from websites and saving it in a database.
- web scraping is a process of extracting data from websites and saving it in a file.

# 2. why web scraping
- web scraping is used to extract data from websites.
- web scraping is used to extract data from websites and save it in a structured format.
- web scraping is used to extract data from websites and save it in a database.
- web scraping is used to extract data from websites and save it in a file.
- web scraping is used to extract data from websites and analyze it.
- web scraping is used to extract data from websites and visualize it.

# 3. how to do web scraping
- web scraping can be done using web scraping tools.
- web scraping can be done using web scraping libraries.
- web scraping can be done using web scraping frameworks.
- web scraping can be done using web scraping APIs.
- web scraping can be done using web scraping services.
- web scraping can be done using web scraping software.
- web scraping can be done using web scraping scripts.

# 4. web scraping tools
- web scraping tools are software programs that are used to extract data from websites.
1 web scraping using python libraries(BeautifulSoup, Scrapy, Selenium)
2 web scraping using r libraries(rvest, RSelenium)
3 web scraping using php libraries(Goutte, Simple HTML DOM Parser)
4 web scraping using javascript libraries(Puppeteer, Cheerio)
5 web scraping using java libraries(JSoup, Selenium)
6 web scraping using c# libraries(HtmlAgilityPack, Selenium)


# 5. web scraping libraries
- web scraping libraries are software programs that are used to extract data from websites.
- like BeautifulSoup, Scrapy, Selenium, rvest, RSelenium, Goutte, Simple HTML DOM Parser, Puppeteer, Cheerio, JSoup, HtmlAgilityPack, Selenium


# 6. what type of data can be scraped from websites
- text data
- image data
- video data
- audio data
- pdf data
- csv data
- excel data
- json data
- xml data
- html data
- table data
- list data
- link data

# 7. what can do with the web scraping ?












# in this clsas we wil start to learn web scraping using python 

#---------------------------------#
# what is web scraping?
# web scraping is a process of extracting data from the websites.
# it is a process of extracting data from the web pages.(HTML, XML, JSON, etc.)
# it is a process of extracting data from the web documents.(HTML, XML, JSON, etc.)
# it is a process of extracting data from the web servers.(HTTP, HTTPS, FTP, etc.)
# it is a process of extracting data from the web services.(SOAP, REST, XML, JSON, etc.)
# it is a process of extracting data from the web APIs.(Application Programming Interface)
# it is a process of extracting data from the web applications. (Web 2.0, Web 3.0, etc.)
# it is a process of extracting data from the web browsers. (Chrome, Firefox, Safari, etc.)
# it is a process of extracting data from the web search engines. (Google, Bing, Yahoo, etc.)
# it is a process of extracting data from the web directories. (Yellow Pages, Just Dial, etc.)
# it is a process of extracting data from the web portals. (Amazon, Flipkart, etc.)
# it is a process of extracting data from the web databases. (SQL, NoSQL, etc.)
# it is a process of extracting data from the web storages. (Cloud, Local, etc.)


#---------------------------------#

# what is web crawling?
# web crawling is a process of navigating the web pages.(HTML, XML, JSON, etc.)
# navigatting means moving from one page to another page.(Hyperlink, URL, etc.)
# it is a process of navigating the web documents.(HTML, XML, JSON, etc.)
# it is a process of navigating the web servers.(HTTP, HTTPS, FTP, etc.)
# it is a process of navigating the web services.(SOAP, REST, XML, JSON, etc.)
# it is a process of navigating the web APIs.(Application Programming Interface)

# ---------------------------------#

# what is web scraping used for?
# web scraping is used for extracting data from the websites.
# after extracting data we can use it for data analysis.
# and data visualization. and data mining and data science. for machine learning and deep learning.modeling and prediction.
# we can use it for data entry and data migration.
# we can use it for data integration and data transformation.

#---------------------------------#
# how to do web scraping?
# we can do web scraping using programming languages.
# we can do web scraping using python, R etc.
# we can do web scraping using libraries and frameworks.(BeautifulSoup, Scrapy, Selenium, etc.)
# we can do web scraping using tools and software.(Octoparse, ParseHub, etc.)

#---------------------------------#

# what are the tools for web scraping?
# using python libraries.
# Beautiful Soup(pyhton library)
# Scrapy (python library)
# Selenium (python library)


# using R libraries.
# rvest (R library)
# httr (R library)
# RSelenium (R library)


# using software.
# Octoparse (software is open source)
# ParseHub (software is open source)
# WebHarvy (software is open source)
# Mozenda (software is open source)
# Diffbot (software is open source)
# OutWit Hub (software is open source)
# FMiner (software is open source)
# Content Grabber (software is open source)
# WebSundew (software is open source)   
# Web Content Extractor (software is open source)

#---------------------------------#
# what are the best practices for web scraping?
# always respect the robots.txt file. (it is a file which is created by the website owner to tell the web crawlers which pages or files the 
# crawler can or can't request from the website.)
# always respect the terms and conditions of the website.
# always respect the privacy policy of the website.
# always respect the copyright policy of the website.
# always respect the security policy of the website.
# always respect the ethical policy of the website.
# always respect the legal policy of the website.
# always respect the data policy of the website.
# always respect the access policy of the website.

#---------------------------------#
# types of web scraping? 
# there are two types of web scraping.
# 1. Manual Web Scraping (by human E.g. Copy and Paste, etc.)
# 2. Automated Web Scraping (by computer E.g. Python, R, etc.)

# --------------------------------#
# is we can do web scraping without permission?
# yes we can do web scraping without permission. like (public data, open data, etc.)

#---------------------------------#
# is web scraping is a hacking?

# yes web scraping is a hacking. because we are extracting data from the websites without permission.

# is web scraping is a data theft?

# yes web scraping is a data theft. because we are stealing data from the websites.

# is we can fatch live data from web scraping?

# yes we can fatch live data from web scraping. like (stock market, weather, news, etc.)
# for live data we have to use web scraping tools and software.(Octoparse, ParseHub, etc.)
# and we have to use web scraping libraries and frameworks.(BeautifulSoup, Scrapy, Selenium, etc.) 
# in which we can write the code to fatch live data.
# best libray is BeautifulSoup. because it is easy to use and easy to learn. 

#---------------------------------#
# using a webscrping we can store data in differnet format like (CSV, Excel, JSON, etc.)
# we can store data in the database like (SQL, NoSQL, etc.)
# we can store data in the cloud like (AWS, Azure, Google Cloud, etc.)
# we can store data in the local like (Hard Disk, Pendrive, etc.)
# we can store data in the web server like (HTTP, HTTPS, FTP, etc.)
# we can store data in the web services like (SOAP, REST, XML, JSON, etc.)
# we can store data in the web APIs like (Application Programming Interface)



#---------------------------------#
# what are the challenges of web scraping?
# 1. Dynamic Web Pages
# 2. JavaScript
# 3. AJAX
# 4. Cookies
# 5. Sessions
# 6. Captcha
# 7. IP Blocking
# 8. Proxy Blocking
# 9. User-Agent Blocking
# 10. Robots.txt
# 11. Terms and Conditions
# 12. Privacy Policy
# 13. Copyright Policy
# 14. Security Policy
# 15. Ethical Policy
# 16. Legal Policy
# 17. Data Policy
# 18. Access Policy
# 19. Data Theft


#---------------------------------#
# what are the benefits of web scraping?
# 1. Data Extraction
# 2. Data Analysis
# 3. Data Visualization
# 4. Data Mining
# 5. Data Science
# 6. Machine Learning (tarining and testing model)
# 7. Deep Learning (tarining and testing model)
# 8. Data Entry
# 9. Data Migration
# 10. Data Integration
# 11. Data Transformation


#---------------------------------#


graph TD
    A[Source Code<br>(hello.c)]:::source --> B[Preprocessor<br>(cpp)]:::process
    B --> C[Preprocessed Code]:::file
    C --> D[Compiler<br>(cc1)]:::process
    D --> E[Assembly Code<br>(hello.s)]:::file
    E --> F[Assembler<br>(as)]:::process
    F --> G[Object Code<br>(hello.o)]:::file
    G --> H[Linker<br>(ld)]:::process
    H --> I[Executable<br>(a.out or hello)]:::executable

    classDef source fill:#f9f,stroke:#333,stroke-width:2px,color:#000;
    classDef process fill:#bbf,stroke:#333,stroke-width:2px,color:#000;
    classDef file fill:#f96,stroke:#333,stroke-width:2px,color:#000;
    classDef executable fill:#6f9,stroke:#333,stroke-width:2px,color:#000;


    